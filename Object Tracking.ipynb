{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4872e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Video, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a9143",
   "metadata": {},
   "source": [
    "1. Read Video Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d88fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_file = \"DATA/STGEORGES.avi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599f202e",
   "metadata": {},
   "source": [
    "Since the browser can't read avi files, we'll read the video (STGEORGES) using opencv's function `VideoCapture` and show it frame by frame. It's necessary to know the framerate of the video in order to include the appropriate pause between each frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32cf9cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Framerate 8.0\n"
     ]
    }
   ],
   "source": [
    "# Read the video from the file\n",
    "source = cv2.VideoCapture(video_file)\n",
    "\n",
    "framerate = source.get(5)\n",
    "\n",
    "print(\"Framerate:\", framerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb46603",
   "metadata": {},
   "source": [
    "Since the frame rate is 8, it's important to include a 125ms pause between each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ebc5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(source.isOpened()):\n",
    "    ret, frame = source.read()\n",
    "    if ret==True:\n",
    "        cv2.imshow('Frame',frame)\n",
    "        cv2.waitKey(125)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "source.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf63563",
   "metadata": {},
   "source": [
    "2. Transform to grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf6f15",
   "metadata": {},
   "source": [
    "To transform the video to grayscale, we follow the same process as the previous but before showing each frame, we convert it to grayscale and save it to a new file. We use `VideoWriter_fourcc` for the video format and `VideoWriter` to write the new video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "990bae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = cv2.VideoCapture(video_file)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "grayscale = cv2.VideoWriter('gray.avi',fourcc, 8., (352,288))\n",
    "\n",
    "while(source.isOpened()):\n",
    "    ret, frame = source.read()\n",
    "    if ret==True:\n",
    "        # convert the current frame to grayscale\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # reconvert it to BGR to have three channels (the image will still not have colors)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # write to the new file\n",
    "        grayscale.write(frame.astype('uint8'))\n",
    "        cv2.imshow('Frame',frame)\n",
    "        cv2.waitKey(125)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "source.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c90730",
   "metadata": {},
   "source": [
    "3. Reduce framerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc28041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = cv2.VideoCapture(\"gray.avi\")\n",
    "\n",
    "low_fr = cv2.VideoWriter('gray_lower_framerate.avi',\n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                         4., (352,288))\n",
    "\n",
    "frames = []\n",
    "while(source.isOpened()):\n",
    "    ret, frame = source.read()\n",
    "    if ret==True:\n",
    "        \n",
    "        frames.append(frame)\n",
    "        # write to the new file\n",
    "        low_fr.write(frame.astype('uint8'))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f4a34",
   "metadata": {},
   "source": [
    "4. Video sequence from PIETON images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cdb9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "pieton = cv2.VideoWriter(\n",
    "    'pieton.avi',\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    8.,\n",
    "    (320,275))\n",
    "\n",
    "# we have 16 images\n",
    "for i in range(1, 16):\n",
    "    # reach each frame\n",
    "    frame = cv2.imread(\"DATA/PIETON{}.bmp\".format(i))\n",
    "\n",
    "    try:\n",
    "        # Write the output video \n",
    "        pieton.write(frame.astype('uint8'))\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame',frame)\n",
    "    except:\n",
    "        print(\"Error processing the frame\")\n",
    "\n",
    "pieton.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc9452",
   "metadata": {},
   "source": [
    "5. Object tracking on the PIETON video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10466861",
   "metadata": {},
   "source": [
    "For the object tracking, we will use the HOG descriptor for people detection and use the bounding box coordinates to trace the objects movement.\n",
    "\n",
    "There are two people on the video, before the detection starts, the user must choose either left or right by clicking the left or right arrow in order to detect the person on the left or the right.\n",
    "\n",
    "An example of the tracking of the person on the right is on the file pieton_track_right.avi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92046507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception\n",
      "exception\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "cv2.startWindowThread()\n",
    "\n",
    "out = cv2.VideoWriter(\n",
    "    'pieton_track_right.avi',\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    8.,\n",
    "    (320,275))\n",
    "\n",
    "cv2.imshow(\"image\",cv2.imread(\"DATA/PIETON1.bmp\"))\n",
    "key = cv2.waitKey()\n",
    "\n",
    "pts = np.array([] ,np.int32)\n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "\n",
    "for i in range(1, 16):\n",
    "    frame = cv2.imread(\"DATA/PIETON{}.bmp\".format(i))\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # detect people in the image\n",
    "    # returns the bounding boxes for the detected objects\n",
    "    boxes, weights = hog.detectMultiScale(frame, winStride=(4,4) )\n",
    "    \n",
    "    boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "    \n",
    "    try:\n",
    "\n",
    "        if(key == 83):\n",
    "            boxes_select = max(box[0] for box in boxes)\n",
    "        elif(key == 81):\n",
    "            boxes_select = min(box[0] for box in boxes)\n",
    "        else:\n",
    "            boxes_select = max(box[0] for box in boxes)\n",
    "            \n",
    "        boxes = [box for box in boxes if box[0] == boxes_select]\n",
    "\n",
    "        for (xA, yA, xB, yB) in boxes:\n",
    "            # display the detected boxes \n",
    "            cv2.rectangle(frame, (xA, yA), (xB, yB),\n",
    "                              (0, 255, 0), 2)\n",
    "            point = [int((xA+xB)/2), int((yA+yB)/2)]\n",
    "            pts = np.append(pts, point)\n",
    "            pts = pts.reshape((-1, 1, 2))\n",
    "            cv2.polylines(frame, [pts],\n",
    "                      False, color, thickness)\n",
    "        # Write the output video \n",
    "        out.write(frame.astype('uint8'))\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    except:\n",
    "        print(\"exception\")\n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
